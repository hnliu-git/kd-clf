
# Data module configs
data:
  batch_size: 32
  max_length: 128
  num_workers: 0

# Distillation configs

distillation:
  epochs: 10
  adaptors:
    - 'AttnMiniLM'
    - 'ValMiniLM'
    - 'LogitMSE'
  temperature: 4
  learning_rate: 3e-5
  weight_decay: 5e-5
  eps: 1e-8


# Weight-and-bias config
wandb:
  project: knowledge-distillation-multilingual
  exp: test

ckpt_path: ckpts/

