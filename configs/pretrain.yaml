
# Data module configs
data:
  batch_size: 8
  num_workers: 4
  mlm_prob: 0.15
  max_seq_length: 256
  cache_dir: /content/drive/MyDrive/thesis/cache
  tokenizer: bert-base-uncased


# Weight-and-bias config
wandb:
  project: pretrain
  exp: test

# The model
hidden_size: 144
hidden_layers: 2
atten_heads: 12