
# Weight-and-bias config
wandb:
  project: pretrain
  exp: test

# Data module configs
data:
  dataset_name: tweet_eval
  dataset_cfgs: emotion
  tokenizer: bert-base-uncased
  batch_size: 32
  max_length: 128
  mlm_prob: 0.15
  num_workers: 4
#  load_data_dir: /content/drive/MyDrive/thesis/cache/wikipedia_processed
  save_data_dir: /media/haonan/PROJECT/Ubuntu/processed/${data.dataset_name}
  cache_dir: /media/haonan/PROJECT/Ubuntu/cache

# Pre-trained configs
epochs: 20

# The model
model: configs/bert_uncased_a12/tiny.yaml