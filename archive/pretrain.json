{
  "model_type": "bert",
  "do_train": true,
  "do_eval": true,
  "preprocessing_num_workers": 8,
  "per_device_train_batch_size": 128,
  "mlm_probability": 0.2,
  "warmup_ratio": 0.01,
  "max_seq_length": 512,
  "overwrite_output_dir": true,
  "dataset_config_name": "sst2",
  "output_dir": "pretrain",
  "dataset_name": "glue",
  "tokenizer_name": "bert-base-uncased",
  "config_overrides": "hidden_size=144,num_attention_heads=12,num_hidden_layers=2"
}